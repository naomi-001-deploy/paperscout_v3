# app_v6_openai.py â€“ Paperscout (Nur API-Version)
# UI-Update: Modernes Design mit CSS-Karten und Tabs.
# BUGFIX: StreamlitDuplicateElementId durch eindeutige Button-Labels behoben.
# BUGFIX: HTML-Escaping-Problem im Abstract (f-string-Konflikt) endgÃ¼ltig behoben.
# BUGFIX: Synchronisierung zwischen "Alle auswÃ¤hlen"-Buttons und individuellen Checkboxen.
# FEATURE (NEU): Dynamische Farbgebung (Dark Mode / Light Mode) durch Streamlit CSS-Variablen.

import os, re, html, json, smtplib, ssl, hashlib
from email.mime.text import MIMEText
from email.utils import formataddr
import streamlit as st
import pandas as pd
import httpx
from functools import lru_cache
from io import BytesIO
from datetime import date, datetime, timedelta
from typing import List, Optional, Dict, Any
from urllib.parse import quote_plus

# --- Excel-Engine Detection (xlsxwriter / openpyxl) ---
try:
Â  Â  import xlsxwriter Â 
Â  Â  _HAS_XLSXWRITER = True
except Exception:
Â  Â  _HAS_XLSXWRITER = False

try:
Â  Â  import openpyxl Â 
Â  Â  _HAS_OPENPYXL = True
except Exception:
Â  Â  _HAS_OPENPYXL = False

def _pick_excel_engine() -> str | None:
Â  Â  """Bevorzugt xlsxwriter; fÃ¤llt auf openpyxl zurÃ¼ck; None wenn beides fehlt."""
Â  Â  if _HAS_XLSXWRITER:
Â  Â  Â  Â  return "xlsxwriter"
Â  Â  if _HAS_OPENPYXL:
Â  Â  Â  Â  return "openpyxl"
Â  Â  return None

def _stable_sel_key(r: dict, i: int) -> str:
Â  Â  # robuste Basis: DOI -> URL -> Titel -> Index
Â  Â  basis = (str(r.get("doi") or "") + "|" +
Â  Â  Â  Â  Â  Â  Â str(r.get("url") or "") + "|" +
Â  Â  Â  Â  Â  Â  Â str(r.get("title") or "")).lower()
Â  Â  # kurze, saubere ID
Â  Â  h = hashlib.sha1(basis.encode("utf-8")).hexdigest()[:12]
Â  Â  return f"sel_card_{h}_{i}"

# --- SMTP aus Secrets/Env laden (robust, auch wenn keine secrets.toml vorhanden ist) ---
def setup_smtp_from_secrets_or_env():
Â  Â  try:
Â  Â  Â  Â  import streamlit as st
Â  Â  Â  Â  secrets_obj = getattr(st, "secrets", None)
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  _ = secrets_obj.get("_probe_", None) if hasattr(secrets_obj, "get") else None
Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  secrets_obj = None
Â  Â  except Exception:
Â  Â  Â  Â  secrets_obj = None

Â  Â  def read_secret(key: str) -> Optional[str]:
Â  Â  Â  Â  if secrets_obj is None:
Â  Â  Â  Â  Â  Â  return None
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  val = secrets_obj[key]
Â  Â  Â  Â  Â  Â  val = str(val).strip()
Â  Â  Â  Â  Â  Â  return val if val else None
Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  return None

Â  Â  def setdef(key: str, default: Optional[str] = None):
Â  Â  Â  Â  val = read_secret(key)
Â  Â  Â  Â  if val is None:
Â  Â  Â  Â  Â  Â  val = os.environ.get(key)
Â  Â  Â  Â  if val is None:
Â  Â  Â  Â  Â  Â  val = default
Â  Â  Â  Â  if val is not None:
Â  Â  Â  Â  Â  Â  os.environ[key] = str(val)

Â  Â  setdef("EMAIL_HOST", "smtp.gmail.com")
Â  Â  setdef("EMAIL_PORT", "587")
Â  Â  setdef("EMAIL_USE_TLS", "true")
Â  Â  setdef("EMAIL_USE_SSL", "false")
Â  Â  setdef("EMAIL_FROM")
Â  Â  setdef("EMAIL_USER")
Â  Â  setdef("EMAIL_PASSWORD")
Â  Â  setdef("EMAIL_SENDER_NAME", "paperscout")

setup_smtp_from_secrets_or_env()

# =========================
# App-Konfiguration
# =========================
st.set_page_config(page_title="paperscout UI", layout="wide")

HARDCODED_KEY = "sk-proj..."
HARDCODED_CROSSREF_MAIL = ""
if HARDCODED_KEY:
Â  Â  os.environ["PAPERSCOUT_OPENAI_API_KEY"] = HARDCODED_KEY
if HARDCODED_CROSSREF_MAIL:
Â  Â  os.environ["CROSSREF_MAILTO"] = HARDCODED_CROSSREF_MAIL

# =========================
# HTTP Basics
# =========================
def _headers(extra: Optional[Dict[str, str]] = None) -> Dict[str, str]:
Â  Â  mailto = os.getenv("CROSSREF_MAILTO") or "you@example.com"
Â  Â  base = {
Â  Â  Â  Â  "User-Agent": (
Â  Â  Â  Â  Â  Â  "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) "
Â  Â  Â  Â  Â  Â  "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"
Â  Â  Â  Â  ),
Â  Â  Â  Â  "Accept": "text/html,application/json;q=0.9,*/*;q=0.8",
Â  Â  Â  Â  "Accept-Language": "de-DE,de;q=0.9,en;q=0.8",
Â  Â  Â  Â  "Referer": "https://www.google.com/",
Â  Â  Â  Â  "From": mailto,
Â  Â  }
Â  Â  if extra:
Â  Â  Â  Â  base.update(extra)
Â  Â  return base

def fetch_html(url: str, timeout: float = 25.0) -> Optional[str]:
Â  Â  try:
Â  Â  Â  Â  base_headers = _headers({
Â  Â  Â  Â  Â  Â  "Cache-Control": "no-cache",
Â  Â  Â  Â  Â  Â  "Pragma": "no-cache",
Â  Â  Â  Â  Â  Â  "Upgrade-Insecure-Requests": "1",
Â  Â  Â  Â  })
Â  Â  Â  Â  with _http_client(timeout=timeout, headers=base_headers) as c:
Â  Â  Â  Â  Â  Â  r = c.get(url)
Â  Â  Â  Â  Â  Â  if r.status_code == 403:
Â  Â  Â  Â  Â  Â  Â  Â  # Domain-spezifische Referrer als Retry
Â  Â  Â  Â  Â  Â  Â  Â  domain_ref = None
Â  Â  Â  Â  Â  Â  Â  Â  if "wiley.com" in url: domain_ref = "https://onlinelibrary.wiley.com/"
Â  Â  Â  Â  Â  Â  Â  Â  elif "sagepub.com" in url: domain_ref = "https://journals.sagepub.com/"
Â  Â  Â  Â  Â  Â  Â  Â  elif "sciencedirect.com" in url: domain_ref = "https://www.sciencedirect.com/"
Â  Â  Â  Â  Â  Â  Â  Â  elif "journals.aom.org" in url: domain_ref = "https://journals.aom.org/"
Â  Â  Â  Â  Â  Â  Â  Â  if domain_ref:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  r = c.get(url, headers=_headers({"Referer": domain_ref}))
Â  Â  Â  Â  Â  Â  if r.status_code in (403, 429):
Â  Â  Â  Â  Â  Â  Â  Â  alt_headers = dict(base_headers)
Â  Â  Â  Â  Â  Â  Â  Â  alt_headers["User-Agent"] = (
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117 Safari/537.36"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  r = c.get(url, headers=alt_headers)
Â  Â  Â  Â  Â  Â  r.raise_for_status()
Â  Â  Â  Â  Â  Â  return r.text or ""
Â  Â  except Exception:
Â  Â  Â  Â  return None

Â  Â  Â  Â Â 
# --- Proxy-UnterstÃ¼tzung (HTTP/HTTPS/SOCKS) ---
def _proxy_dict() -> Optional[dict]:
Â  Â  """
Â  Â  Liest einen optionalen Proxy aus:
Â  Â  - ENV: PAPERSCOUT_PROXY (z. B. 'http://user:pass@host:port' oder 'socks5://host:1080')
Â  Â  - Session: st.session_state['proxy_url'] (wird im UI gesetzt)
Â  Â  Gibt ein httpx-kompatibles proxies-Dict zurÃ¼ck oder None.
Â  Â  """
Â  Â  p = (st.session_state.get("proxy_url") or
Â  Â  Â  Â  Â os.getenv("PAPERSCOUT_PROXY") or "").strip()
Â  Â  if not p:
Â  Â  Â  Â  return None
Â  Â  return {"http": p, "https": p}

def _http_client(timeout: float, headers: dict | None = None) -> httpx.Client:
Â  Â  """
Â  Â  Einheitlicher httpx-Client:
Â  Â  - http2=False (Publisher liefern unter H2 anderes Markup)
Â  Â  - follow_redirects=True
Â  Â  - optionaler Proxy (HTTP/HTTPS/SOCKS)
Â  Â  - Cookie-Handling (NEU/VERBESSERT)
Â  Â  """
Â  Â  return httpx.Client(
Â  Â  Â  Â  timeout=timeout,
Â  Â  Â  Â  headers=headers or _headers(),
Â  Â  Â  Â  follow_redirects=True,
Â  Â  Â  Â  http2=False,
Â  Â  Â  Â  proxies=_proxy_dict(),
Â  Â  Â  Â  cookies=httpx.Cookies(), Â # <-- VERBESSERUNG
Â  Â  )


TAG_STRIP = re.compile(r"<[^>]+>")
def _clean_text(s: str) -> str:
Â  Â  s = html.unescape(s or "")
Â  Â  s = TAG_STRIP.sub(" ", s)
Â  Â  s = re.sub(r"\s+", " ", s).strip()
Â  Â  s = re.sub(r"^(abstract|zusammenfassung)\s*[:\-]\s*", "", s, flags=re.I)
Â  Â  return s

def parse_date_any(s: Optional[str]) -> Optional[str]:
Â  Â  if not s: return None
Â  Â  s = s.strip()
Â  Â  fmts = ["%Y-%m-%d","%Y/%m/%d","%d %B %Y","%B %Y","%Y-%m","%Y"]
Â  Â  for f in fmts:
Â  Â  Â  Â  try: return datetime.strptime(s,f).strftime("%Y-%m-%d")
Â  Â  Â  Â  except Exception: pass
Â  Â  m=re.search(r"(\d{4})",s)
Â  Â  return f"{m.group(1)}-01-01" if m else None

# =========================
# API-Schnittstellen
# =========================
CR_BASE = "https://api.crossref.org"

JOURNAL_ISSN: Dict[str, str] = {
Â  Â  "The Leadership Quarterly": "1048-9843",
Â  Â  "Human Relations": "0018-7267",
Â  Â  "Organization Studies": "0170-8406",
Â  Â  "Organizational Research Methods": "1094-4281",
Â  Â  "Journal of Organizational Behavior": "0894-3796",
Â  Â  "Journal of Management Studies": "0022-2380",
Â  Â  "Personnel Psychology": "0031-5826",
Â  Â  "European Management Review": "1740-4754",
Â  Â  "Organization Science": "1047-7039",
Â  Â  "Management Science": "0025-1909",
Â  Â  "Academy of Management Journal": "0001-4273",
Â  Â  "Zeitschrift fÃ¼r Arbeits- und Organisationspsychologie": "0932-4089",
Â  Â  "Journal of Applied Psychology": "0021-9010",
Â  Â  "Journal of Personality and Social Psychology": "0022-3514",
Â  Â  "Journal of Occupational Health Psychology": "1076-8998",
Â  Â  "Journal of Management": "0149-2063",
Â  Â  "Strategic Management Journal": "0143-2095",
}

# =========================
# Crossref â€“ erweiterte Fallbacks (ALT_ISSN + flexibler fetch_crossref_any)
# =========================
ALT_ISSN: Dict[str, List[str]] = {
Â  Â  "Journal of Applied Psychology": ["1939-1854"],
Â  Â  "Journal of Personality and Social Psychology": ["1939-1315"],
Â  Â  "Journal of Occupational Health Psychology": ["1939-1307"],
Â  Â  "Journal of Management": ["1557-1211"],
Â  Â  "Human Relations": ["1741-282X"],
Â  Â  "Personnel Psychology": ["1744-6570"],
Â  Â  "Journal of Management Studies": ["1467-6486"],
Â  Â  "European Management Review": ["1740-4762"],
Â  Â  "Academy of Management Journal": ["1948-0989"],
Â  Â  "The Leadership Quarterly": ["1873-3409"],
Â  Â  "Organizational Research Methods": ["1552-7425"],
}

def fetch_crossref_any(journal: str, issn: str, since: str, until: str, rows: int) -> List[Dict[str, Any]]:
Â  Â  """
Â  Â  Robustere Crossref-Abfrage:
Â  Â  - Probiert verschiedene Datumsfilter.
Â  Â  - FÃ¤llt zurÃ¼ck auf Container-Title-Query und ALT_ISSN.
Â  Â  - Letzter Notanker: ohne Datumsfilter (wir filtern client-seitig).
Â  Â  - Filtert auf type:journal-article.
Â  Â  - harter Nachfilter: exakter Container-Title ODER ISSN-Match.
Â  Â  """
Â  Â  mailto = os.getenv("CROSSREF_MAILTO") or "you@example.com"
Â  Â  base_filters = [
Â  Â  Â  Â  ("from-pub-date", "until-pub-date"),
Â  Â  Â  Â  ("from-online-pub-date", "until-online-pub-date"),
Â  Â  Â  Â  ("from-print-pub-date", "until-print-pub-date"),
Â  Â  ]

Â  Â  def _mk_urls(_issn: str, with_dates: bool) -> List[str]:
Â  Â  Â  Â  if with_dates:
Â  Â  Â  Â  Â  Â  url_list: List[str] = []
Â  Â  Â  Â  Â  Â  for f_from, f_until in base_filters:
Â  Â  Â  Â  Â  Â  Â  Â  filt = f"{f_from}:{since},{f_until}:{until},type:journal-article"
Â  Â  Â  Â  Â  Â  Â  Â  url_list.extend([
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"{CR_BASE}/journals/{_issn}/works?filter={filt}&sort=published&order=desc&rows={rows}&mailto={mailto}",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"{CR_BASE}/works?filter=issn:{_issn},{filt}&sort=published&order=desc&rows={rows}&mailto={mailto}",
Â  Â  Â  Â  Â  Â  Â  Â  ])
Â  Â  Â  Â  Â  Â  for f_from, f_until in base_filters:
Â  Â  Â  Â  Â  Â  Â  Â  filt = f"{f_from}:{since},{f_until}:{until},type:journal-article"
Â  Â  Â  Â  Â  Â  Â  Â  url_list.append(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"{CR_BASE}/works?query.container-title={quote_plus(journal)}&filter={filt}&sort=published&order=desc&rows={rows}&mailto={mailto}"
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  return url_list
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  return [
Â  Â  Â  Â  Â  Â  Â  Â  f"{CR_BASE}/journals/{_issn}/works?filter=type:journal-article&sort=published&order=desc&rows={rows}&mailto={mailto}",
Â  Â  Â  Â  Â  Â  Â  Â  f"{CR_BASE}/works?filter=issn:{_issn},type:journal-article&sort=published&order=desc&rows={rows}&mailto={mailto}",
Â  Â  Â  Â  Â  Â  Â  Â  f"{CR_BASE}/works?query.container-title={quote_plus(journal)}&filter=type:journal-article&sort=published&order=desc&rows={rows}&mailto={mailto}",
Â  Â  Â  Â  Â  Â  ]

Â  Â  issn_candidates = [issn] + ALT_ISSN.get(journal, [])

Â  Â  urls: List[str] = []
Â  Â  for issn_try in issn_candidates:
Â  Â  Â  Â  urls.extend(_mk_urls(issn_try, with_dates=True))
Â  Â  for issn_try in issn_candidates:
Â  Â  Â  Â  urls.extend(_mk_urls(issn_try, with_dates=False))

Â  Â  def _row_from_item(it: Dict[str, Any]) -> Dict[str, Any]:
Â  Â  Â  Â  issued = None
Â  Â  Â  Â  dp = (it.get("issued", {}) or {}).get("date-parts", [])
Â  Â  Â  Â  if dp and dp[0]:
Â  Â  Â  Â  Â  Â  issued = "-".join(map(str, dp[0]))
Â  Â  Â  Â  if not issued:
Â  Â  Â  Â  Â  Â  issued = parse_date_any(it.get("created", {}).get("date-time", "")) or ""
Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  "title": " ".join(it.get("title") or []),
Â  Â  Â  Â  Â  Â  "doi": it.get("DOI", ""),
Â  Â  Â  Â  Â  Â  "issued": parse_date_any(issued) or "",
Â  Â  Â  Â  Â  Â  "journal": " ".join(it.get("container-title") or []),
Â  Â  Â  Â  Â  Â  "authors": ", ".join(
Â  Â  Â  Â  Â  Â  Â  Â  " ".join([a.get("given", ""), a.get("family", "")]).strip()
Â  Â  Â  Â  Â  Â  Â  Â  for a in it.get("author", [])
Â  Â  Â  Â  Â  Â  ),
Â  Â  Â  Â  Â  Â  "abstract": _clean_text(it.get("abstract", "")),
Â  Â  Â  Â  Â  Â  "url": it.get("URL", ""),
Â  Â  Â  Â  }

Â  Â  def _within(d: str) -> bool:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  return (since <= d <= until)
Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  return True

Â  Â  j_norm = re.sub(r"\s+", " ", (journal or "")).strip().lower()
Â  Â  issn_set = set(issn_candidates)

Â  Â  def _same_journal(it: Dict[str, Any]) -> bool:
Â  Â  Â  Â  ct = " ".join(it.get("container-title") or [])
Â  Â  Â  Â  ct_norm = re.sub(r"\s+", " ", ct).strip().lower()
Â  Â  Â  Â  it_issn = set(it.get("ISSN") or [])
Â  Â  Â  Â  return (ct_norm == j_norm) or bool(it_issn & issn_set)

Â  Â  for url in urls:
Â  Â  Â  Â  try:
Â  Â  Â  Â  Â  Â  with httpx.Client(timeout=30, headers=_headers()) as c:
Â  Â  Â  Â  Â  Â  Â  Â  r = c.get(url)
Â  Â  Â  Â  Â  Â  Â  Â  r.raise_for_status()
Â  Â  Â  Â  Â  Â  Â  Â  items = r.json().get("message", {}).get("items", [])
Â  Â  Â  Â  Â  Â  Â  Â  if not items:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  Â  Â  Â  Â  items = [it for it in items if _same_journal(it)]
Â  Â  Â  Â  Â  Â  Â  Â  if not items:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  Â  Â  Â  Â  rows_out = [_row_from_item(it) for it in items]

Â  Â  Â  Â  Â  Â  Â  Â  if "type:journal-article" in url and "from-" not in url:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rows_out = [x for x in rows_out if x.get("issued") and _within(x["issued"])]

Â  Â  Â  Â  Â  Â  Â  Â  if rows_out:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  return rows_out
Â  Â  Â  Â  except Exception:
Â  Â  Â  Â  Â  Â  pass

Â  Â  return []

# =========================
# KEIN TOC-SCRAPING MEHR
# =========================


# -------------------------
# Crossref / Semantic Scholar / OpenAlex / OpenAI
# -------------------------
def fetch_semantic(doi:str)->Optional[Dict[str, Any]]:
Â  Â  api=f"https://api.semanticscholar.org/graph/v1/paper/DOI:{doi}?fields=title,abstract,authors,year,venue,url"
Â  Â  try:
Â  Â  Â  Â  r=httpx.get(api,timeout=15)
Â  Â  Â  Â  if r.status_code!=200:return None
Â  Â  Â  Â  js=r.json()
Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  "title":js.get("title",""),
Â  Â  Â  Â  Â  Â  "abstract":js.get("abstract",""),
Â  Â  Â  Â  Â  Â  "authors":", ".join(a.get("name","") for a in js.get("authors",[])),
Â  Â  Â  Â  Â  Â  "issued":str(js.get("year",""))+"-01-01",
Â  Â  Â  Â  Â  Â  "journal":js.get("venue",""),
Â  Â  Â  Â  Â  Â  "url":js.get("url","")
Â  Â  Â  Â  }
Â  Â  except Exception:return None

def fetch_openalex(doi:str)->Optional[Dict[str, Any]]:
Â  Â  api=f"https://api.openalex.org/works/DOI:{doi}"
Â  Â  try:
Â  Â  Â  Â  r=httpx.get(api,timeout=15)
Â  Â  Â  Â  if r.status_code!=200:return None
Â  Â  Â  Â  js=r.json()
Â  Â  Â  Â  abs_text=""
Â  Â  Â  Â  if "abstract_inverted_index" in js:
Â  Â  Â  Â  Â  Â  abs_text=" ".join(sum(js["abstract_inverted_index"].values(),[]))
Â  Â  Â  Â  return {
Â  Â  Â  Â  Â  Â  "title":js.get("title",""),
Â  Â  Â  Â  Â  Â  "abstract":_clean_text(abs_text),
Â  Â  Â  Â  Â  Â  "authors":", ".join(a.get("author",{}).get("display_name","") for a in js.get("authorships",[])),
Â  Â  Â  Â  Â  Â  "issued":str(js.get("publication_year",""))+"-01-01",
Â  Â  Â  Â  Â  Â  "journal":js.get("host_venue",{}).get("display_name",""),
Â  Â  Â  Â  Â  Â  "url":js.get("doi","")
Â  Â  Â  Â  }
Â  Â  except Exception:return None

def ai_extract_metadata_from_html(html_text:str,model:str)->Optional[Dict[str, Any]]:
Â  Â  key=os.getenv("PAPERSCOUT_OPENAI_API_KEY") or os.getenv("OPENAI_API_KEY")
Â  Â  if not key:return None
Â  Â  try:
Â  Â  Â  Â  from openai import OpenAI
Â  Â  Â  Â  client=OpenAI(api_key=key)
Â  Â  Â  Â  prompt=("Extract JSON with keys {title,doi,authors,issued,journal,abstract}. "
Â  Â  Â  Â  Â  Â  Â  Â  "Abstract only from given HTML, no guessing. HTML:\n\n")
Â  Â  Â  Â  resp=client.chat.completions.create(
Â  Â  Â  Â  Â  Â  model=model,
Â  Â  Â  Â  Â  Â  messages=[
Â  Â  Â  Â  Â  Â  Â  Â  {"role":"system","content":"You extract clean metadata from article HTML."},
Â  Â  Â  Â  Â  Â  Â  Â  {"role":"user","content":prompt+html_text[:100000]}
Â  Â  Â  Â  Â  Â  ],
Â  Â  Â  Â  Â  Â  temperature=0,
Â  Â  Â  Â  Â  Â  response_format={"type":"json_object"}
Â  Â  Â  Â  )
Â  Â  Â  Â  data=json.loads(resp.choices[0].message.content)
Â  Â  Â  Â  for k,v in data.items():
Â  Â  Â  Â  Â  Â  data[k]=_clean_text(str(v))
Â  Â  Â  Â  data["issued"]=parse_date_any(data.get("issued","")) or ""
Â  Â  Â  Â  return data
Â  Â  except Exception:return None

# -------------------------
# GENERISCHE ABSTRACT-EXTRAKTION AUS HTML (AMJ/Highwire, Wiley, SAGE, APA)
# -------------------------
def extract_abstract_from_html_simple(html_text: str) -> Optional[str]:
Â  Â  if not html_text:
Â  Â  Â  Â  return None
Â  Â  m = re.search(r'<meta[^>]+name=["\']citation_abstract["\'][^>]+content=["\']([^"\']+)["\']', html_text, flags=re.I)
Â  Â  if m:
Â  Â  Â  Â  return _clean_text(m.group(1))
Â  Â  m = re.search(r'<meta[^>]+name=["\']dc\.description["\'][^>]+content=["\']([^"\']+)["\']', html_text, flags=re.I)
Â  Â  if m:
Â  Â  Â  Â  return _clean_text(m.group(1))
Â  Â  m = re.search(r'<meta[^>]+property=["\']og:description["\'][^>]+content=["\']([^"\']+)["\']', html_text, flags=re.I)
Â  Â  if m:
Â  Â  Â  Â  return _clean_text(m.group(1))

Â  Â  m = re.search(r'<div[^>]+class=["\'][^"\']*hlFld-Abstract[^"\']*["\'][^>]*>(.*?)</div>', html_text, flags=re.I|re.S)
Â  Â  if m:
Â  Â  Â  Â  return _clean_text(m.group(1))
Â  Â  m = re.search(r'<section[^>]+class=["\'][^"\']*abstract[^"\']*["\'][^>]*>(.*?)</section>', html_text, flags=re.I|re.S)
Â  Â  if m:
Â  Â  Â  Â  return _clean_text(m.group(1))
Â  Â  m = re.search(r'<div[^>]+id=["\']abstract["\'][^>]*>(.*?)</div>', html_text, flags=re.I|re.S)
Â  Â  if m:
Â  Â  Â  Â  return _clean_text(m.group(1))
Â  Â  return None

# -------------------------
# ScienceDirect / Elsevier â€“ direkter JSON-Endpoint
# -------------------------
def fetch_sciencedirect_abstract(doi_or_url: str) -> Optional[str]:
Â  Â  m = re.search(r"(S\d{16,})", doi_or_url)
Â  Â  pii = m.group(1) if m else None
Â  Â  if not pii:
Â  Â  Â  Â  html_text = fetch_html(doi_or_url)
Â  Â  Â  Â  if html_text:
Â  Â  Â  Â  Â  Â  m = re.search(r'/pii/(S\d{16,})', html_text)
Â  Â  Â  Â  Â  Â  if m:
Â  Â  Â  Â  Â  Â  Â  Â  pii = m.group(1)
Â  Â  if not pii:
Â  Â  Â  Â  return None

Â  Â  api_url = f"https://www.sciencedirect.com/sdfe/arp/pii/{pii}"
Â  Â  try:
Â  Â  Â  Â  r = httpx.get(api_url, headers=_headers(), timeout=15)
Â  Â  Â  Â  if r.status_code != 200:
Â  Â  Â  Â  Â  Â  return None
Â  Â  Â  Â  js = r.json()
Â  Â  Â  Â  abstract_html = js.get("abstracts", [{}])[0].get("content", "")
Â  Â  Â  Â  return _clean_text(abstract_html)
Â  Â  except Exception:
Â  Â  Â  Â  return None

# -------------------------
# KEINE TOC-FILTER-TOOLS MEHR
# -------------------------

# =========================
# Hauptpipeline
# =========================
def collect_all(journal: str, since: str, until: str, rows: int, ai_model: str) -> List[Dict[str, Any]]:
Â  Â  issn = JOURNAL_ISSN.get(journal)
Â  Â  if not issn:
Â  Â  Â  Â  return []

Â  Â  base = fetch_crossref_any(journal, issn, since, until, rows)
Â  Â  out: List[Dict[str, Any]] = []

Â  Â  if not base:
Â  Â  Â  Â  return []

Â  Â  for rec in base:
Â  Â  Â  Â  if rec.get("abstract"):
Â  Â  Â  Â  Â  Â  out.append(rec)
Â  Â  Â  Â  Â  Â  continue

Â  Â  Â  Â  doi = rec.get("doi", "")

Â  Â  Â  Â  for fn in (fetch_semantic, fetch_openalex):
Â  Â  Â  Â  Â  Â  if not doi:
Â  Â  Â  Â  Â  Â  Â  Â  break
Â  Â  Â  Â  Â  Â  data = fn(doi)
Â  Â  Â  Â  Â  Â  if data and data.get("abstract"):
Â  Â  Â  Â  Â  Â  Â  Â  for k in ["title", "authors", "journal", "issued", "abstract", "url"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not rec.get(k):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rec[k] = data.get(k)
Â  Â  Â  Â  Â  Â  Â  Â  break

Â  Â  Â  Â  if not rec.get("abstract"):
Â  Â  Â  Â  Â  Â  # PrÃ¼fen, ob "sciencedirect" in der URL ist ODER ob das Journal
Â  Â  Â  Â  Â  Â  # (gemÃ¤ÃŸ ISSN) ein Sciencedirect-Journal ist.
Â  Â  Â  Â  Â  Â  is_sd_url = "sciencedirect.com" in (rec.get("url","") or "")
Â  Â  Â  Â  Â  Â  # (Wir haben JOURNAL_REGISTRY nicht mehr, also machen wir einen
Â  Â  Â  Â  Â  Â  # Workaround und checken, ob die ISSN zu TLQ gehÃ¶rt)
Â  Â  Â  Â  Â  Â  is_sd_journal = (issn == "1048-9843") # The Leadership Quarterly
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if is_sd_url or is_sd_journal:
Â  Â  Â  Â  Â  Â  Â  Â  abs_text = fetch_sciencedirect_abstract(rec.get("url") or rec.get("doi",""))
Â  Â  Â  Â  Â  Â  Â  Â  if abs_text:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rec["abstract"] = abs_text

Â  Â  Â  Â  if not rec.get("abstract") and rec.get("url"):
Â  Â  Â  Â  Â  Â  html_text = fetch_html(rec["url"])
Â  Â  Â  Â  Â  Â  if html_text:
Â  Â  Â  Â  Â  Â  Â  Â  abs_simple = extract_abstract_from_html_simple(html_text)
Â  Â  Â  Â  Â  Â  Â  Â  if abs_simple:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rec["abstract"] = abs_simple

Â  Â  Â  Â  if not rec.get("abstract") and rec.get("url"):
Â  Â  Â  Â  Â  Â  html_text = fetch_html(rec["url"])
Â  Â  Â  Â  Â  Â  if html_text:
Â  Â  Â  Â  Â  Â  Â  Â  ai = ai_extract_metadata_from_html(html_text, ai_model)
Â  Â  Â  Â  Â  Â  Â  Â  if ai:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  for k in ["title", "authors", "journal", "issued", "abstract", "doi", "url"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  if not rec.get(k) and ai.get(k):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  rec[k] = ai.get(k)

Â  Â  Â  Â  out.append(rec)

Â  Â  for r in out:
Â  Â  Â  Â  d = (r.get("doi") or "").strip()
Â  Â  Â  Â  if d.startswith("10."):
Â  Â  Â  Â  Â  Â  r["doi"] = f"https://doi.org/{d}"
Â  Â  Â  Â  elif d.startswith("http://doi.org/"):
Â  Â  Â  Â  Â  Â  r["doi"] = "https://" + d[len("http://"):]
Â  Â  Â  Â  if not r.get("url"):
Â  Â  Â  Â  Â  Â  r["url"] = r.get("doi", "")

Â  Â  return out

def dedup(items: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
Â  Â  seen=set();out=[]
Â  Â  for a in items:
Â  Â  Â  Â  d=(a.get("doi") or "").lower()
Â  Â  Â  Â  if d in seen: continue
Â  Â  Â  Â  seen.add(d); out.append(a)
Â  Â  return out

# =========================
# E-Mail Versand (SMTP)
# =========================
def send_doi_email(to_email: str, dois: List[str], sender_display: Optional[str] = None) -> tuple[bool, str]:
Â  Â  host = os.getenv("EMAIL_HOST")
Â  Â  port = int(os.getenv("EMAIL_PORT", "587"))
Â  Â  user = os.getenv("EMAIL_USER")
Â  Â  password = os.getenv("EMAIL_PASSWORD")
Â  Â  sender_addr = os.getenv("EMAIL_FROM") or user
Â  Â  default_name = os.getenv("EMAIL_SENDER_NAME", "paperscout")
Â  Â  use_tls = os.getenv("EMAIL_USE_TLS", "true").lower() in ("1","true","yes","y")
Â  Â  use_ssl = os.getenv("EMAIL_USE_SSL", "false").lower() in ("1,""true","yes","y")

Â  Â  if not (host and port and sender_addr and user and password):
Â  Â  Â  Â  return False, "SMTP nicht konfiguriert (EMAIL_HOST/PORT/USER/PASSWORD/EMAIL_FROM)."

Â  Â  display_name = (sender_display or "").strip() or default_name

Â  Â  body_lines = [
Â  Â  Â  Â  "Hallo,",
Â  Â  Â  Â  "",
Â  Â  Â  Â  f"ausgewÃ¤hlt von: {display_name}",
Â  Â  Â  Â  "",
Â  Â  Â  Â  "Hier ist die Liste der ausgewÃ¤hlten DOIs:",
Â  Â  Â  Â  *[f"- {d if d.startswith('10.') else d}" for d in dois],
Â  Â  Â  Â  "",
Â  Â  Â  Â  "Viele GrÃ¼ÃŸe",
Â  Â  Â  Â  display_name,
Â  Â  ]
Â  Â  msg = MIMEText("\n".join(body_lines), _charset="utf-8")
Â  Â  msg["Subject"] = f"[paperscout] {len(dois)} DOI(s) â€” {display_name}"
Â  Â  msg["From"] = formataddr((display_name, sender_addr))
Â  Â  msg["To"] = to_email

Â  Â  try:
Â  Â  Â  Â  if use_ssl:
Â  Â  Â  Â  Â  Â  context = ssl.create_default_context()
Â  Â  Â  Â  Â  Â  with smtplib.SMTP_SSL(host, port, context=context) as server:
Â  Â  Â  Â  Â  Â  Â  Â  server.login(user, password)
Â  Â  Â  Â  Â  Â  Â  Â  server.sendmail(sender_addr, [to_email], msg.as_string())
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  with smtplib.SMTP(host, port) as server:
Â  Â  Â  Â  Â  Â  Â  Â  server.ehlo()
Â  Â  Â  Â  Â  Â  Â  Â  if use_tls:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  server.starttls(context=ssl.create_default_context())
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  server.ehlo()
Â  Â  Â  Â  Â  Â  Â  Â  server.login(user, password)
Â  Â  Â  Â  Â  Â  Â  Â  server.sendmail(sender_addr, [to_email], msg.as_string())

Â  Â  Â  Â  return True, "E-Mail gesendet."
Â  Â  except Exception as e:
Â  Â  Â  Â  return False, f"E-Mail Versand fehlgeschlagen: {e}"

# =========================
# =========================
# NEUE UI (v3) - JETZT MIT DARK MODE
# =========================
# =========================
st.title("ğŸ•µğŸ» paperscout â€“ Journal Service")

# Init Session State fÃ¼r Auswahl
if "selected_dois" not in st.session_state:
Â  Â  st.session_state["selected_dois"] = set()

# --- KORREKTUR: CSS-Block (v3) fÃ¼r Dark Mode ---
# Verwendet jetzt Streamlit CSS-Variablen fÃ¼r dynamische Farben
CARD_STYLE_V3 = """
<style>
Â  Â  /*
Â  Â  NEUE THEME-AWARE KARTEN (v3)
Â  Â  Verwendet Streamlit CSS-Variablen, um sich an Light/Dark-Mode anzupassen.
Â  Â  */
Â  Â  .result-card {
Â  Â  Â  Â  /* Nimmt die "Hintergrundfarbe fÃ¼r Container" (hellgrau/dunkelgrau) */
Â  Â  Â  Â  background-color: var(--secondary-background-color);Â 
Â  Â  Â  Â  border: 1px solid var(--secondary-background-color); /* Rand in gleicher Farbe */
Â  Â  Â  Â  border-left: 6px solid var(--primary-color); /* Akzentfarbe (z.B. blau) */
Â  Â  Â  Â  border-radius: 8px;
Â  Â  Â  Â  padding: 1.1rem;
Â  Â  Â  Â  margin-bottom: 1rem;
Â  Â  Â  Â  /* Subtiler Schatten, der auf beiden Modi funktioniert */
Â  Â  Â  Â  box-shadow: 0 2px 8px rgba(0,0,0,0.05);Â 
Â  Â  Â  Â  transition: all 0.2s ease-in-out;
Â  Â  }
Â  Â  .result-card:hover {
Â  Â  Â  Â  /* Heller/dunkler als der Hintergrund, je nach Modus */
Â  Â  Â  Â  background-color: var(--background-color);Â 
Â  Â  Â  Â  box-shadow: 0 5px 15px rgba(0,0,0,0.1);
Â  Â  Â  Â  transform: translateY(-2px);
Â  Â  }
Â  Â  .result-card h3 {
Â  Â  Â  Â  color: var(--text-color); /* Passt sich an (schwarz/weiÃŸ) */
Â  Â  Â  Â  margin-top: 0;
Â  Â  Â  Â  margin-bottom: 0.25rem;
Â  Â  }
Â  Â  .result-card .meta {
Â  Â  Â  Â  color: var(--secondary-text-color); /* Passt sich an (grau) */
Â  Â  Â  Â  font-size: 0.9rem;
Â  Â  Â  Â  margin-bottom: 0.75rem;
Â  Â  }
Â  Â  .result-card .authors {
Â  Â  Â  Â  color: var(--text-color); /* Passt sich an (schwarz/weiÃŸ) */
Â  Â  Â  Â  font-size: 0.95rem;
Â  Â  Â  Â  font-weight: 500;
Â  Â  }
Â  Â  .result-card details {
Â  Â  Â  Â  margin-top: 1rem;
Â  Â  }
Â  Â  .result-card details summary {
Â  Â  Â  Â  cursor: pointer;
Â  Â  Â  Â  font-weight: bold;
Â  Â  Â  Â  color: var(--primary-color); /* Nutzt die Akzentfarbe des Themes */
Â  Â  Â  Â  font-size: 0.95rem;
Â  Â  Â  Â  list-style-type: 'â• ';
Â  Â  }
Â  Â  .result-card details[open] summary {
Â  Â  Â  Â  list-style-type: 'â– ';
Â  Â  }
Â  Â  .result-card details > div {
Â  Â  Â  Â  /* Nimmt die Haupt-Hintergrundfarbe (weiÃŸ/sehr dunkelgrau) */
Â  Â  Â  Â  background-color: var(--background-color);Â 
Â  Â  Â  Â  border-radius: 5px;
Â  Â  Â  Â  padding: 0.75rem 1rem;
Â  Â  Â  Â  margin-top: 0.5rem;
Â  Â  Â  Â  /* Rand ist jetzt die "normale" Randfarbe */
Â  Â  Â  Â  border: 1px solid var(--border-color, var(--gray-300));Â 
Â  Â  }
Â  Â Â 
Â  Â  /* Expliziter Fallback fÃ¼r Rand im Dark Mode (falls --border-color nicht gesetzt ist) */
Â  Â  html.dark .result-card details > div {
Â  Â  Â  Â  border: 1px solid var(--border-color, var(--gray-800));
Â  Â  }
Â  Â Â 
Â  Â  .result-card details .abstract {
Â  Â  Â  Â  color: var(--text-color); /* Passt sich an */
Â  Â  Â  Â  white-space: pre-wrap;
Â  Â  Â  Â  font-size: 0.9rem;
Â  Â  Â  Â  line-height: 1.6;
Â  Â  }
Â  Â  .result-card details a {
Â  Â  Â  Â  color: var(--primary-color); /* Links nutzen auch Akzentfarbe */
Â  Â  Â  Â  text-decoration: none;
Â  Â  }
Â  Â  .result-card details a:hover {
Â  Â  Â  Â  text-decoration: underline;
Â  Â  }
</style>
"""
st.markdown(CARD_STYLE_V3, unsafe_allow_html=True)


# --- Setup-Tabs ---
tab1, tab2 = st.tabs(["ğŸ” Schritt 1: Auswahl", "âš™ï¸ Schritt 2: Einstellungen"])
journals = sorted(JOURNAL_ISSN.keys())
today = date.today()

with tab1:
Â  Â  st.markdown("#### Journals auswÃ¤hlen")
Â  Â Â 
Â  Â  def _chk_key(name: str) -> str:
Â  Â  Â  Â  return "chk_" + re.sub(r"\W+", "_", name.lower()).strip("_")

Â  Â  sel_all_col, desel_all_col, _ = st.columns([1, 1, 4])
Â  Â  with sel_all_col:
Â  Â  Â  Â  select_all_clicked = st.button("Alle **Journals** auswÃ¤hlen", use_container_width=True)
Â  Â  with desel_all_col:
Â  Â  Â  Â  deselect_all_clicked = st.button("Alle **Journals** abwÃ¤hlen", use_container_width=True)

Â  Â  if select_all_clicked:
Â  Â  Â  Â  for j in journals:
Â  Â  Â  Â  Â  Â  st.session_state[_chk_key(j)] = True
Â  Â  if deselect_all_clicked:
Â  Â  Â  Â  for j in journals:
Â  Â  Â  Â  Â  Â  st.session_state[_chk_key(j)] = False

Â  Â  chosen: List[str] = []
Â  Â  cols = st.columns(3)
Â  Â  for idx, j in enumerate(journals):
Â  Â  Â  Â  k = _chk_key(j)
Â  Â  Â  Â  current_val = st.session_state.get(k, False)
Â  Â  Â  Â  with cols[idx % 3]:
Â  Â  Â  Â  Â  Â  if st.checkbox(j, value=current_val, key=k):
Â  Â  Â  Â  Â  Â  Â  Â  chosen.append(j)

Â  Â  st.markdown(f"**{len(chosen)}** Journal(s) ausgewÃ¤hlt.")
Â  Â  st.divider()
Â  Â Â 
Â  Â  st.markdown("#### Zeitraum definieren")
Â  Â  date_col1, date_col2, date_col3 = st.columns(3)
Â  Â  with date_col1:
Â  Â  Â  Â  since = st.date_input("Seit (inkl.)", value=date(today.year, 1, 1))
Â  Â  with date_col2:
Â  Â  Â  Â  until = st.date_input("Bis (inkl.)", value=today)
Â  Â  with date_col3:
Â  Â  Â  Â  st.markdown("<br>", unsafe_allow_html=True) # Kleiner Layout-Hack fÃ¼r die HÃ¶he
Â  Â  Â  Â  last30 = st.checkbox("Nur letzte 30 Tage", value=False)
Â  Â  Â  Â  if last30:
Â  Â  Â  Â  Â  Â  st.caption(f"Aktiv: {(today - timedelta(days=30)).isoformat()} bis {today.isoformat()}")

with tab2:
Â  Â  st.markdown("#### Technische Einstellungen")
Â  Â  rows = st.number_input("Max. Treffer pro Journal", min_value=5, max_value=200, step=5, value=100)
Â  Â  ai_model = st.text_input("OpenAI Modell (fÃ¼r Abstract-Fallback)", value="gpt-4o-mini")
Â  Â Â 
Â  Â  st.markdown("#### API-Keys & E-Mails")
Â  Â  api_key_input = st.text_input("ğŸ”‘ OpenAI API-Key", type="password", value="", help="Optional. Wird fÃ¼r Artikel ohne Abstract benÃ¶tigt.")
Â  Â  if api_key_input:
Â  Â  Â  Â  os.environ["PAPERSCOUT_OPENAI_API_KEY"] = api_key_input
Â  Â  Â  Â  st.caption("API-Key fÃ¼r diese Sitzung gesetzt.")
Â  Â  Â  Â Â 
Â  Â  crossref_mail = st.text_input("ğŸ“§ Crossref Mailto (empfohlen)", value=os.getenv("CROSSREF_MAILTO", ""), help="Eine E-Mail-Adresse verbessert die ZuverlÃ¤ssigkeit der Crossref-API.")
Â  Â  if crossref_mail:
Â  Â  Â  Â  os.environ["CROSSREF_MAILTO"] = crossref_mail
Â  Â  Â  Â  st.caption("Crossref-Mailto fÃ¼r diese Sitzung gesetzt.")

Â  Â  st.markdown("#### Netzwerk & Versand")
Â  Â  proxy_url = st.text_input("ğŸŒ Proxy (optional)", value=os.getenv("PAPERSCOUT_PROXY", ""), help="Format: http://user:pass@host:port")
Â  Â  if proxy_url:
Â  Â  Â  Â  st.session_state["proxy_url"] = proxy_url.strip()
Â  Â  Â  Â  st.success("Proxy fÃ¼r diese Sitzung aktiv.")
Â  Â  else:
Â  Â  Â  Â  st.session_state["proxy_url"] = ""

Â  Â  with st.expander("âœ‰ï¸ E-Mail Versand (Status)", expanded=False):
Â  Â  Â  Â  ok = all(os.getenv(k) for k in ["EMAIL_HOST","EMAIL_PORT","EMAIL_USER","EMAIL_PASSWORD","EMAIL_FROM"])
Â  Â  Â  Â  if ok:
Â  Â  Â  Â  Â  Â  st.success(f"SMTP konfiguriert fÃ¼r: {os.getenv('EMAIL_FROM')}")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.error("SMTP nicht vollstÃ¤ndig konfiguriert. Bitte Secrets/Env setzen.")

st.divider()

# --- Start-Button ---
run_col1, run_col2, run_col3 = st.columns([2, 1, 2])
with run_col2:
Â  Â  run = st.button("ğŸš€ LetÂ´s go! Metadaten ziehen", use_container_width=True, type="primary")

if run:
Â  Â  if not chosen:
Â  Â  Â  Â  st.warning("Bitte mindestens ein Journal in Schritt 1 auswÃ¤hlen.")
Â  Â  else:
Â  Â  Â  Â  st.info("Starte Abruf â€” Crossref, Semantic Scholar, OpenAlex, KI-Fallback...")

Â  Â  Â  Â  all_rows: List[Dict[str, Any]] = []
Â  Â  Â  Â  progress = st.progress(0, "Starte...")
Â  Â  Â  Â  n = len(chosen)

Â  Â  Â  Â  if last30:
Â  Â  Â  Â  Â  Â  s_since = (today - timedelta(days=30)).isoformat()
Â  Â  Â  Â  Â  Â  s_until = today.isoformat()
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  s_since, s_until = str(since), str(until)

Â  Â  Â  Â  for i, j in enumerate(chosen, 1):
Â  Â  Â  Â  Â  Â  progress.progress(min(i / max(n, 1), 1.0), f"({i}/{n}) Verarbeite: {j}")
Â  Â  Â  Â  Â  Â  rows_j = collect_all(j, s_since, s_until, int(rows), ai_model)
Â  Â  Â  Â  Â  Â  rows_j = dedup(rows_j)
Â  Â  Â  Â  Â  Â  all_rows.extend(rows_j)

Â  Â  Â  Â  progress.empty()
Â  Â  Â  Â  if not all_rows:
Â  Â  Â  Â  Â  Â  st.warning("Keine Treffer im gewÃ¤hlten Zeitraum/Journals gefunden.")
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  df = pd.DataFrame(all_rows)
Â  Â  Â  Â  Â  Â  cols = [c for c in ["title", "doi", "issued", "journal", "authors", "abstract", "url"] if c in df.columns]
Â  Â  Â  Â  Â  Â  if cols:
Â  Â  Â  Â  Â  Â  Â  Â  df = df[cols]

Â  Â  Â  Â  Â  Â  st.session_state["results_df"] = df
Â  Â  Â  Â  Â  Â  st.session_state["selected_dois"] = set() # Auswahl zurÃ¼cksetzen
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Alle Checkbox-States lÃ¶schen/zurÃ¼cksetzen, falls alte Keys von einem frÃ¼heren Lauf existieren
Â  Â  Â  Â  Â  Â  for key in list(st.session_state.keys()):
Â  Â  Â  Â  Â  Â  Â  Â  if key.startswith("sel_card_"):
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  del st.session_state[key]
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  st.success(f"ğŸ‰ {len(df)} Treffer geladen!")

# ================================
# --- NEUE ERGEBNISANZEIGE (v2) ---
# ================================
st.divider()

# --- NEU: Anker fÃ¼r "Hoch" ---
st.markdown("<a id='results_top'></a>", unsafe_allow_html=True) 

st.subheader("ğŸ“š Ergebnisse")

# --- NEU: Link fÃ¼r "Runter" ---
# Kleiner CSS-Hack, um den Link rechtsbÃ¼ndig Ã¼ber den Buttons zu platzieren
st.markdown(
    """
    <style>
        .link-container {
            text-align: right;
            margin-top: -2.5rem; 
            margin-bottom: 1rem;
        }
        .link-container a {
            text-decoration: none;
            font-size: 0.9rem;
        }
    </style>
    <div class="link-container">
        <a href='#actions_bottom'>â¬‡ï¸ Zum E-Mail Versand springen</a>
    </div>
    """, 
    unsafe_allow_html=True
)


# --- KORREKTUR 1 (Sync-Fix): Angepasste Callback-Funktion ---
def toggle_doi(doi, key):
Â  Â  # Diese Funktion wird *nach* dem Klick ausgefÃ¼hrt.
Â  Â  # st.session_state[key] enthÃ¤lt jetzt den *neuen* Status.
Â  Â  is_checked = st.session_state.get(key, False)
Â  Â  if is_checked:
Â  Â  Â  Â  st.session_state["selected_dois"].add(doi)
Â  Â  else:
Â  Â  Â  Â  st.session_state["selected_dois"].discard(doi)
# --- ENDE KORREKTUR 1 ---


if "results_df" in st.session_state and not st.session_state["results_df"].empty:
Â  Â  df = st.session_state["results_df"].copy()

Â  Â  def _to_http(u: str) -> str:
Â  Â  Â  Â  if not isinstance(u, str): return ""
Â  Â  Â  Â  u = u.strip()
Â  Â  Â  Â  if u.startswith("http://doi.org/"): return "https://" + u[len("http://"):]
Â  Â  Â  Â  if u.startswith("http"): return u
Â  Â  Â  Â  if u.startswith("10."): return "https://doi.org/" + u
Â  Â  Â  Â  return u

Â  Â  if "url" in df.columns:
Â  Â  Â  Â  df["link"] = df["url"].apply(_to_http)
Â  Â  elif "doi" in df.columns:
Â  Â  Â  Â  df["link"] = df["doi"].apply(_to_http)
Â  Â  else:
Â  Â  Â  Â  df["link"] = ""

Â  Â  if "selected_dois" not in st.session_state:
Â  Â  Â  Â  st.session_state["selected_dois"] = set()

Â  Â  st.caption("Klicke links auf die Checkbox, um EintrÃ¤ge fÃ¼r den E-Mail-Versand auszuwÃ¤hlen.")

Â  Â  # --- KORREKTUR 2 (Sync-Fix): Logik fÃ¼r "Alle auswÃ¤hlen/abwÃ¤hlen" ---
Â  Â  # Wir mÃ¼ssen *vor* den Buttons eine Map aller DOIs und Keys erstellen.
Â  Â  doi_key_map = {}
Â  Â  for i, (_, r) in enumerate(df.iterrows(), start=1):
Â  Â  Â  Â  doi_norm = (r.get("doi", "") or "").lower()
Â  Â  Â  Â  if doi_norm:
Â  Â  Â  Â  Â  Â  sel_key = _stable_sel_key(r, i)
Â  Â  Â  Â  Â  Â  doi_key_map[doi_norm] = sel_key
Â  Â  # --- ENDE KORREKTUR 2 ---


Â  Â  # --- Aktionen: Auswahl & Download ---
Â  Â  action_col1, action_col2, action_col3 = st.columns([1, 1, 1])
Â  Â  with action_col1:
Â  Â  Â  Â  st.metric(label="Aktuell ausgewÃ¤hlt", value=f"{len(st.session_state['selected_dois'])} / {len(df)}")
Â  Â Â 
Â  Â  with action_col2:
Â  Â  Â  Â  if st.button("Alle **Ergebnisse** auswÃ¤hlen", use_container_width=True):
Â  Â  Â  Â  Â  Â  # --- KORREKTUR 3 (Sync-Fix): Button-Logik aktualisiert ---
Â  Â  Â  Â  Â  Â  for doi, key in doi_key_map.items():
Â  Â  Â  Â  Â  Â  Â  Â  st.session_state[key] = True Â # Setzt den Status der individuellen Checkbox
Â  Â  Â  Â  Â  Â  st.session_state["selected_dois"] = set(doi_key_map.keys()) # Setzt die Master-Liste
Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  # --- ENDE KORREKTUR 3 ---

Â  Â  with action_col3:
Â  Â  Â  Â  if st.button("Alle **Ergebnisse** abwÃ¤hlen", use_container_width=True):
Â  Â  Â  Â  Â  Â  # --- KORREKTUR 4 (Sync-Fix): Button-Logik aktualisiert ---
Â  Â  Â  Â  Â  Â  for key in doi_key_map.values():
Â  Â  Â  Â  Â  Â  Â  Â  if key in st.session_state:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.session_state[key] = False # Setzt den Status der individuellen Checkbox
Â  Â  Â  Â  Â  Â  st.session_state["selected_dois"].clear() # Leert die Master-Liste
Â  Â  Â  Â  Â  Â  st.rerun()
Â  Â  Â  Â  Â  Â  # --- ENDE KORREKTUR 4 ---
Â  Â Â 
Â  Â  st.markdown("---") # Visueller Trenner

Â  Â  # --- Ergebnis-Loop (Neue Karten v2) ---
Â  Â  for i, (_, r) in enumerate(df.iterrows(), start=1):
Â  Â  Â  Â  doi_val = str(r.get("doi", "") or "")
Â  Â  Â  Â  doi_norm = doi_val.lower()
Â  Â  Â  Â  link_val = _to_http(r.get("link", "") or doi_val)
Â  Â  Â  Â  title = r.get("title", "") or "(ohne Titel)"
Â  Â  Â  Â  journal = r.get("journal", "") or ""
Â  Â  Â  Â  issued = r.get("issued", "") or ""
Â  Â  Â  Â  authors = r.get("authors", "") or ""
Â  Â  Â  Â  abstract = r.get("abstract", "") or ""

Â  Â  Â  Â  left, right = st.columns([0.07, 0.93])
Â  Â  Â  Â Â 
Â  Â  Â  Â  # Checkbox in der linken Spalte
Â  Â  Â  Â  with left:
Â  Â  Â  Â  Â  Â  sel_key = _stable_sel_key(r, i) # 'i' startet bei 1, passt zu KORREKTUR 2
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if doi_norm: # Nur Checkbox anzeigen, wenn eine DOI vorhanden ist
Â  Â  Â  Â  Â  Â  Â  Â  # --- KORREKTUR 5 (Sync-Fix): Checkbox an on_change binden ---
Â  Â  Â  Â  Â  Â  Â  Â  st.checkbox(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  " ", # Leeres Label
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # 'value' wird jetzt ignoriert, da der Status
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Ã¼ber den 'key' und die 'on_change' callbacks gesteuert wird.
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  # Wir setzen es trotzdem fÃ¼r die initiale Erstellung.
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  value=st.session_state.get(sel_key, False), # Holt den aktuellen Status
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  key=sel_key,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  label_visibility="hidden", # Versteckt das leere Label
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  on_change=toggle_doi, Â  Â  Â # <--- WICHTIG
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  args=(doi_norm, sel_key) Â  # <--- WICHTIG (Ã¼bergibt DOI und KEY)
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  # --- ENDE KORREKTUR 5 ---

Â  Â  Â  Â  # Gestaltete Karte in der rechten Spalte
Â  Â  Â  Â  with right:
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # HTML-sichere Inhalte erstellen
Â  Â  Â  Â  Â  Â  title_safe = html.escape(title)
Â  Â  Â  Â  Â  Â  meta_safe = html.escape(" Â· ".join([x for x in [journal, issued] if x]))
Â  Â  Â  Â  Â  Â  authors_safe = html.escape(authors)
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # URLs/Links (sollten nicht escaped werden)
Â  Â  Â  Â  Â  Â  doi_safe = _to_http(doi_val)
Â  Â  Â  Â  Â  Â  link_safe = link_val
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # Link-Text (sollte escaped werden)
Â  Â  Â  Â  Â  Â  doi_val_safe = html.escape(doi_val)
Â  Â  Â  Â  Â  Â  link_val_safe = html.escape(link_val)

Â  Â  Â  Â  Â  Â  # HTML fÃ¼r DOI und Link (nur wenn vorhanden)
Â  Â  Â  Â  Â  Â  doi_html = ""
Â  Â  Â  Â  Â  Â  if doi_val:
Â  Â  Â  Â  Â  Â  Â  Â  doi_html = '<b>DOI:</b> <a href="' + doi_safe + '" target="_blank">' + doi_val_safe + '</a><br>'
Â  Â  Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  link_html = ""
Â  Â  Â  Â  Â  Â  if link_val and link_val != doi_safe:
Â  Â  Â  Â  Â  Â  Â  Â  link_html = '<b>URL:</b> <a href="' + link_safe + '" target="_blank">' + link_val_safe + '</a><br>'
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  # HTML fÃ¼r Abstract
Â  Â  Â  Â  Â  Â  if abstract:
Â  Â  Â  Â  Â  Â  Â  Â  abstract_safe = html.escape(abstract)
Â  Â  Â  Â  Â  Â  Â  Â  abstract_html = '<b>Abstract</b><br><p class="abstract">' + abstract_safe + '</p>'
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  abstract_html = "<i>Kein Abstract vorhanden.</i>"

Â  Â  Â  Â  Â  Â  # Die komplette HTML-Karte (sicher mit '+' statt f-string)
Â  Â  Â  Â  Â  Â  card_html = (
Â  Â  Â  Â  Â  Â  Â  Â  '<div class="result-card">'
Â  Â  Â  Â  Â  Â  Â  Â  f'<h3>{title_safe}</h3>'
Â  Â  Â  Â  Â  Â  Â  Â  f'<div class="meta">{meta_safe}</div>'
Â  Â  Â  Â  Â  Â  Â  Â  f'<div class="authors">{authors_safe}</div>'
Â  Â  Â  Â  Â  Â  Â  Â  '<details>'
Â  Â  Â  Â  Â  Â  Â  Â  '<summary>Details anzeigen</summary>'
Â  Â  Â  Â  Â  Â  Â  Â  '<div>' +
Â  Â  Â  Â  Â  Â  Â  Â  doi_html + Â  Â  Â  # Variable sicher mit + einfÃ¼gen
Â  Â  Â  Â  Â  Â  Â  Â  link_html + Â  Â  Â # Variable sicher mit + einfÃ¼gen
Â  Â  Â  Â  Â  Â  Â  Â  '<br>' +
Â  Â  Â  Â  Â  Â  Â  Â  abstract_html + Â # Variable sicher mit + einfÃ¼gen
Â  Â  Â  Â  Â  Â  Â  Â  '</div>'
Â  Â  Â  Â  Â  Â  Â  Â  '</details>'
Â  Â  Â  Â  Â  Â  Â  Â  '</div>'
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  st.markdown(card_html, unsafe_allow_html=True)
Â  Â  Â  Â  Â  Â Â 
Â  Â  st.divider()
    # --- NEU: Link "Hoch" und Anker "Unten" ---
    # Wir nutzen den gleichen CSS-Hack, nur mit angepassten RÃ¤ndern
    st.markdown(
        """
        <style>
            .link-container-bottom {
                text-align: right;
                margin-bottom: -1.5rem;
            }
            .link-container-bottom a {
                text-decoration: none;
                font-size: 0.9rem;
            }
        </style>
        <div class="link-container-bottom">
            <a href='#results_top'>â¬†ï¸ Zum Anfang der Liste springen</a>
        </div>
        """, 
        unsafe_allow_html=True
    )
    # Der Anker, zu dem der "Runter"-Link springt
    st.markdown("<a id='actions_bottom'></a>", unsafe_allow_html=True)
    # --- ENDE NEU ---

Â  Â  # --- Download & E-Mail (neu gruppiert) ---
Â  Â  st.subheader("ğŸ Aktionen: Download & Versand")

Â  Â  dl_col, mail_col = st.columns(2)

Â  Â  with dl_col:
Â  Â  Â  Â  st.markdown("#### â¬‡ï¸ Download")
Â  Â  Â  Â  def df_to_excel_bytes(df_in: pd.DataFrame) -> BytesIO | None:
Â  Â  Â  Â  Â  Â  engine = _pick_excel_engine()
Â  Â  Â  Â  Â  Â  if engine is None: return None
Â  Â  Â  Â  Â  Â  out = BytesIO()
Â  Â  Â  Â  Â  Â  with pd.ExcelWriter(out, engine=engine) as writer:
Â  Â  Â  Â  Â  Â  Â  Â  df_in.to_excel(writer, index=False, sheet_name="results")
Â  Â  Â  Â  Â  Â  out.seek(0)
Â  Â  Â  Â  Â  Â  return out

Â  Â  Â  Â  def _df_to_csv_bytes(df_in: pd.DataFrame) -> BytesIO:
Â  Â  Â  Â  Â  Â  b = BytesIO()
Â  Â  Â  Â  Â  Â  b.write(df_in.to_csv(index=False).encode("utf-8"))
Â  Â  Â  Â  Â  Â  b.seek(0)
Â  Â  Â  Â  Â  Â  return b

Â  Â  Â  Â  x_all = df_to_excel_bytes(df)
Â  Â  Â  Â  if x_all is not None:
Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  "Excel â€” alle Ergebnisse",
Â  Â  Â  Â  Â  Â  Â  Â  data=x_all,
Â  Â  Â  Â  Â  Â  Â  Â  file_name="paperscout_results.xlsx",
Â  Â  Â  Â  Â  Â  Â  Â  mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  "CSV â€” alle Ergebnisse",
Â  Â  Â  Â  Â  Â  Â  Â  data=_df_to_csv_bytes(df),
Â  Â  Â  Â  Â  Â  Â  Â  file_name="paperscout_results.csv",
Â  Â  Â  Â  Â  Â  Â  Â  mime="text/csv",
Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  )

Â  Â  Â  Â  if st.session_state["selected_dois"]:
Â  Â  Â  Â  Â  Â  df_sel = df[df["doi"].astype(str).str.lower().isin(st.session_state["selected_dois"])].copy()
Â  Â  Â  Â  Â  Â  x_sel = df_to_excel_bytes(df_sel)
Â  Â  Â  Â  Â  Â  if x_sel is not None:
Â  Â  Â  Â  Â  Â  Â  Â  st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"Excel â€” {len(st.session_state['selected_dois'])} ausgewÃ¤hlte",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=x_sel,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name="paperscout_selected.xlsx",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â st.download_button(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  f"CSV â€” {len(st.session_state['selected_dois'])} ausgewÃ¤hlte",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  data=_df_to_csv_bytes(df_sel),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  file_name="paperscout_selected.csv",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  mime="text/csv",
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  use_container_width=True
Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  st.button("Excel â€” nur ausgewÃ¤hlte", disabled=True, use_container_width=True)


Â  Â  with mail_col:
Â  Â  Â  Â  st.markdown("#### ğŸ“§ DOI-Liste senden")
Â  Â  Â  Â  with st.container(border=True):
Â  Â  Â  Â  Â  Â  sender_display = st.text_input(
Â  Â  Â  Â  Â  Â  Â  Â  "Absendername (z.B. Naomi oder Ralf)",
Â  Â  Â  Â  Â  Â  Â  Â  value="",
Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  to_email = st.text_input("EmpfÃ¤nger-E-Mail-Adresse", key="doi_email_to")
Â  Â  Â  Â  Â  Â Â 
Â  Â  Â  Â  Â  Â  if st.button("DOI-Liste senden", use_container_width=True, type="primary"):
Â  Â  Â  Â  Â  Â  Â  Â  if not st.session_state["selected_dois"]:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Bitte wÃ¤hle mindestens eine DOI aus.")
Â  Â  Â  Â  Â  Â  Â  Â  elif not to_email or "@" not in to_email:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.warning("Bitte gib eine gÃ¼ltige E-Mail-Adresse ein.")
Â  Â  Â  Â  Â  Â  Â  Â  else:
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ok, msg = send_doi_email(
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  to_email,
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sorted(st.session_state["selected_dois"]),
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  sender_display=sender_display.strip() or None
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  )
Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  st.success(msg) if ok else st.error(msg)

else:
Â  Â  st.info("Noch keine Ergebnisse geladen. WÃ¤hle Journals und klicke auf â€Letâ€™s go!â€œ")
